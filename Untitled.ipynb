{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70002faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que.1\n",
    "'''\n",
    "In Filter Method, features are selected on the basis of statistics measures. This method does not depend on \n",
    "the learning algorithm and chooses the features as a pre-processing step. The filter method filters out the \n",
    "irrelevant feature and redundant columns from the model by using different metrics through ranking.\n",
    "The filter method is simple and fast, and it can handle high-dimensional datasets. However, it has some limitations\n",
    ".It does not take into account the interdependence between the features, and it may select redundant or irrelevant\n",
    "features. Therefore, it is often used in combination with other feature selection techniques such as wrapper and \n",
    "embedded methods to overcome these limitations and improve the performance of the model.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93263bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que2.\n",
    "\n",
    "'''\n",
    "the Filter method evaluates the relevance of each feature independently of the others, while the Wrapper \n",
    "method evaluates the importance of a subset of features by considering their interactions and how they work\n",
    "together to predict the target variable. The Wrapper method can be more computationally expensive than the \n",
    "Filter method, but it can potentially yield better results by taking into account feature interactions.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f25d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que3.\n",
    "\n",
    "#1.\n",
    "'''\n",
    "Lasso regression: Lasso regression is a linear regression model that uses L1 regularization to shrink the \n",
    "coefficients of less important features to zero. This results in a sparse model that selects only the most \n",
    "important features.\n",
    "\n",
    "\n",
    "#2 Elastic net: Elastic net is a linear regression model that combines L1 and L2 regularization to select a\n",
    "subset of features that are both important and not correlated.\n",
    "\n",
    "#3 Ridge regression: Ridge regression is a linear regression model that uses L2 regularization to penalize \n",
    "large coefficients. This results in a model that selects features that are important but not necessarily the\n",
    "most important.\n",
    "\n",
    "#4 Random forests: Random forests are an ensemble learning technique that builds multiple decision trees on\n",
    "bootstrapped samples of the data and selects the most important features based on their contribution to the\n",
    "overall accuracy of the model.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64dd51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que4.\n",
    "'''\n",
    "-Ignoring the interdependence between features\n",
    "-Not considering the impact of feature selection on the overall model\n",
    "-Limited ability to handle non-linear relationships\n",
    "-Limited ability to handle noise and outliers.\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47a1f99b",
   "metadata": {},
   "source": [
    "#Que5.\n",
    "High-dimensional data: The Filter method can handle high-dimensional data efficiently, as it evaluates features independently of each other. This can be an advantage over the Wrapper method, which is computationally expensive and may lead to overfitting if the number of features is large compared to the number of samples.\n",
    "Exploratory data analysis: The Filter method can be used as a first step in exploratory data analysis, as it can provide insights into the relationship between the features and the target variable. The results of the Filter method can be used to guide further analysis, including the use of more advanced feature selection techniques such as the Wrapper method.\n",
    "Simple models: The Filter method can be useful when the model is simple and does not require a large number of features. In this case, selecting the top-ranked features based on the Filter method may be sufficient to obtain a good performance.\n",
    "Linear relationships: The Filter method assumes a linear relationship between features and the target variable. Therefore, if the data has a linear relationship, the Filter method may be a suitable choice for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aaac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que6.\n",
    "'''\n",
    "Firstly i will define the target variable\n",
    "-Select a subset of potential features\n",
    "-Calculate the statistical measure for each feature,\n",
    "-Rank the features\n",
    "- select the top ranked features\n",
    "- validate the model and redefine the feature selection .\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eaba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que7.\n",
    "'''\n",
    "-define the target variable\n",
    "-split the dataset\n",
    "-Choose an appropriate embedded feature selection method\n",
    "-Train the model with all feature\n",
    "-Perform feature selection\n",
    "-Evaluate the performance of the model and refine the feature selection.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
